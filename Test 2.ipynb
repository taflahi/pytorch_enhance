{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloader\n",
    "import numpy as np\n",
    "import network\n",
    "import time\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader.args['train_scales'] = 2\n",
    "dataloader.args['batch_size'] = 1\n",
    "dataloader.args['train'] = 'data/*.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = dataloader.DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network\n",
    "enhancer = network.Enhancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrain\n",
    "pretrain_params = {\n",
    "    'smoothness-weight' : 1e7,\n",
    "    'adversary-weight' : 0.0,\n",
    "    'generator-start' : 0,\n",
    "    'discriminator-start' : 0, #1\n",
    "    'adversarial-start' : 1, #2\n",
    "    'perceptual-weight' : 1e0,\n",
    "    'epochs' : 2, #50\n",
    "    'epoch-size' : 2, #72\n",
    "    'batch-size' : 1, #15\n",
    "    'image-size' : 192,\n",
    "    'zoom' : 2,\n",
    "    'learning-rate': 1e-4,\n",
    "    'discriminator-size' : 64\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.79335885e+09,   4.97336627e+09], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.autograd.Variable(torch.Tensor(2, 1, 24, 24).random_())\n",
    "t.sum(1).sum(1).sum(1).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(enhancer, mode, param):\n",
    "    seed_size = param['image-size'] // param['zoom']\n",
    "    images = np.zeros((param['batch-size'], 3, param['image-size'], param['image-size']), dtype=np.float32)\n",
    "    seeds = np.zeros((param['batch-size'], 3, seed_size, seed_size), dtype=np.float32)\n",
    "    \n",
    "    loader.copy(images, seeds)\n",
    "    # initial lr\n",
    "    lr = network.decay_learning_rate(param['learning-rate'], 75, 0.5)\n",
    "    \n",
    "    #optimizer for generator\n",
    "    opt_gen = optim.Adam(enhancer.generator.parameters(), lr = 0)\n",
    "    \n",
    "    try:\n",
    "        average, start = None, time.time()\n",
    "        for epoch in range(param['epochs']):\n",
    "            adversary_weight = 5e2\n",
    "            \n",
    "            total, stats = None, None\n",
    "            \n",
    "            l_r = next(lr)\n",
    "            network.update_optimizer_lr(opt_gen, l_r)\n",
    "#             network.update_optimizer_lr(opt_disc, l_r)\n",
    "            \n",
    "            for step in range(param['epoch-size']):\n",
    "                enhancer.zero_grad()\n",
    "                loader.copy(images, seeds)\n",
    "                \n",
    "                # run full network once\n",
    "                gen_out, c12, c22, c32, c52, disc_out = enhancer(images, seeds)\n",
    "                \n",
    "                # clone discriminator on the full network\n",
    "                disc = enhancer.discriminator_clone()\n",
    "                disc.zero_grad()\n",
    "                \n",
    "                # optimizer for discriminator\n",
    "                opt_disc = optim.Adam(disc.parameters(), lr=l_r)\n",
    "                opt_disc.state['step'] = epoch * param['epochs'] + step\n",
    "                \n",
    "                # output of new cloned network (maybe you can assert it to equal disc_out)\n",
    "                disc_out2 = disc(c12.detach(), c22.detach(), c32.detach())\n",
    "                disc_out_mean = disc_out2.sum(1).sum(1).sum(1).data.numpy()\n",
    "                stats = stats + disc_out_mean if stats is not None else disc_out_mean \n",
    "                \n",
    "                # compute generator loss\n",
    "                if mode == 'pretrain':\n",
    "                    gen_loss = network.loss_perceptual(c22[:param['batch-size']], c22[param['batch-size']:]) * param['perceptual-weight'] \\\n",
    "                        + network.loss_total_variation(gen_out) * param['smoothness-weight'] \\\n",
    "                        + network.loss_adversarial(disc_out[1:]) * adversary_weight\n",
    "                else:\n",
    "                    gen_loss = network.loss_perceptual(c52[:param['batch-size']], c52[param['batch-size']:]) * param['perceptual-weight'] \\\n",
    "                        + network.loss_total_variation(gen_out) * param['smoothness-weight'] \\\n",
    "                        + network.loss_adversarial(disc_out[1:]) * adversary_weight\n",
    "                \n",
    "                # compute discriminator loss\n",
    "                disc_loss = network.loss_discriminator(disc_out2[:param['batch-size']], disc_out2[param['batch-size']:])\n",
    "                \n",
    "                total = total + gen_loss.data.numpy() if total is not None else gen_loss.data.numpy()\n",
    "                \n",
    "                average = gen_loss.data.numpy() if average is None else average * 0.95 + 0.05 * gen_loss.data.numpy()\n",
    "                print('↑' if gen_loss.data.numpy() > average else '↓', end='', flush=True)\n",
    "            \n",
    "                # update parameters step\n",
    "                \n",
    "                gen_loss.backward()\n",
    "                disc_loss.backward()\n",
    "                \n",
    "                opt_gen.step()\n",
    "                opt_disc.step()\n",
    "                \n",
    "                # rebuild real discriminator from clone\n",
    "                enhancer.assign_back_discriminator(disc)\n",
    "            \n",
    "            total /= param['epoch-size']\n",
    "            stats /= param['epoch-size']\n",
    "            \n",
    "            print('\\nGenerator Loss: ')\n",
    "            print(total)\n",
    "            \n",
    "            real, fake = stats[:param['batch-size']], stats[param['batch-size']:]\n",
    "            print('  - discriminator', real.mean(), len(np.where(real > 0.5)[0]),\n",
    "                                       fake.mean(), len(np.where(fake < -0.5)[0]))\n",
    "            \n",
    "            if epoch == param['adversarial-start'] - 1:\n",
    "                print('  - generator now optimizing against discriminator.')\n",
    "                adversary_weight = param['adversary-weight']\n",
    "                \n",
    "            # Then save every several epochs\n",
    "#             if epoch % 10 == 0:\n",
    "#                 enhancer.save('model/model.pth')\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↓↓\n",
      "Generator Loss: \n",
      "[ 72319.03125]\n",
      "  - discriminator -388.137 0 498.292 0\n",
      "  - generator now optimizing against discriminator.\n",
      "↓↓\n",
      "Generator Loss: \n",
      "[ 48386.765625]\n",
      "  - discriminator -527.849 0 639.15 0\n"
     ]
    }
   ],
   "source": [
    "train(enhancer, 'pretrain', pretrain_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrain\n",
    "train_params = {\n",
    "    'smoothness-weight' : 2e4,\n",
    "    'adversary-weight' : 1e3,\n",
    "    'generator-start' : 5,\n",
    "    'discriminator-start' : 0,\n",
    "    'adversarial-start' : 5, \n",
    "    'perceptual-weight' : 1e0,\n",
    "    'epochs' : 250,\n",
    "    'epoch-size' : 72,\n",
    "    'batch-size' : 15,\n",
    "    'image-size' : 192,\n",
    "    'zoom' : 2,\n",
    "    'learning-rate': 1e-4,\n",
    "    'discriminator-size' : 64\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training do\n",
    "# enhancer.create_new_discriminator(64)\n",
    "# after that call train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pickle\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(enhancer.state_dict(), 'test_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_enhancer = network.Enhancer()\n",
    "new_enhancer.load_state_dict(torch.load('test_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_enhancer.create_new_discriminator(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['params', 'lr', 'betas', 'eps', 'weight_decay'])\n"
     ]
    }
   ],
   "source": [
    "opt_ = optim.Adam(enhancer.parameters(), lr=0.1)\n",
    "for param_group in opt_.param_groups:\n",
    "    print(param_group.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict, {'step': 1})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_.state['step'] = 1\n",
    "opt_.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict, {})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
